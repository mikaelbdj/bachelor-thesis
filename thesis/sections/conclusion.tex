\documentclass[../master/master.tex]{subfiles}
\begin{document}
Having implemented and experimented on the two algorithms we have been working on during the thesis, we can decide on the best symbolic algorithm for strongly connected component analysis. We started by looking at the theoretical analysis of the complexity of the algorithm, which suggested that the Linear algorithm should have performed better in terms of symbolic steps. However, through experiments, we came to the conclusion that the Lockstep algorithm performed slightly better in the average case, suggesting hidden constants in the $\mathcal{O}$- notation of linear that outweighs (in the experimented graph size) the asymptotic advantage it has.

If one has to choose between the vanilla versions, the linear algorithm should be chosen as it performed best time-wise - increasingly so on larger graphs. When adding trimming onto this it comes out on top of all the other 4 algorithms; though lockstep with edge restriction and trimming does come close. Edge restriction did show to have a positive effect in the average case, and thus it should be considered a good improvement to the vanilla Lockstep algorithm. Trimming showed an even better improvement - and contrary to edge restriction there were no case where it worsened the runtime. This heuristic should defintely be applied in practice on both algorithms.

\subsection{Future work}
While we did not have the chance to look at edge restriction and trimming in more depth while writing this thesis, we think it would be very interesting to look into it further.

The effect of edge restriction tended to sometimes be good and sometimes be bad. While our data suggests it would be worth using it in the average case, we think it advantageous to investigate it more in-depth, perhaps looking at the graphs it performed better on. It is possible that edge restriction might be more effective on certain kinds of graphs - perhaps graphs below or above a certain diameter, some number of SCC, the ratio of nodes to edges or the number of BDD nodes.

Trimming on the other hand proved to be very useful, and using it on all graphs would be wise, as it does not harm the performace of the algorithms, and can improve it. What we did notice was that sometimes only running trimming once did not affect the number of symbolic steps or time at all. This is due to the fact that it removes a very small percentage of nodes from the graphs, which does not help the overall performance. The effect of trimming on symbolic steps and time may also vary depending on how interconnected the graph is. It would be worth looking at how many times trimming should be run to optimize its effectiveness. An interesting heuristic to look at would be to continue trimming until trimming only removes a small percentage of nodes; as then it starts being less effective and may take a toll on the overall runtime if done too many times. One could also choose to look at whether performing trimming in between eacg iteration of the algorithm would further improve the runtime.
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master/master"
%%% End:
