\documentclass[../master/master.tex]{subfiles}
\begin{document}
Having implemented and experimented on the two algorithms we have been working on during the thesis, we can decide on the best algorithm for strongly connected component analysis. We have considered different measures of comparing the algorithm. We started by looking at the theoretical analysis of the complexity of the algorithm, which suggested that the Linear algorithm should have performed better in terms of symbolic steps. However, through experiments, we came to the conclusion that the Lockstep algorithm performed slightly better in average-case.

Contrary to our initial assumptions, we learned that between the two vanilla versions of the algorithms, the Linear-time performed better time-wise. The performance was then further improved by trimming, however overall, Lockstep with trimming performed the best.

In our algorithms, we only ran trimming once at the beginning of each algorithm, but even this helped greately. Edge restriction, which was our secind effectiveness measure did help improve the runtime for big graphs, but we discovered that was not the best idea in practice, as it behaved in an unpredictable way on different graphs.

\subsection{Future work}
While we did not have the chance to look at edge restriction and trimming in more depth while writing this thesis, we think it would be very interesting to look into it further.

The effect of edge restriction seemed quite random in our data. While we would generally not suggest using it, we think it would be worth investigating which graphs it performed better on, as there may be some pattern. It is possible that edge restriction does help on some kinds of graphs - perhaps graphs below or above a certain diameter, some number of SCC, the ratio of nodes to edges or the number of BDD nodes.

Trimming on the other hand proved to be very useful, and using it on all graphs would be wise, as it does not harm the performace of the algorithms, and can improve it. What we did notice was that sometimes only running trimming once did not affect the number of symbolic steps or time at all. This is due to the fact that it removes a very small percentage of nodes from the graphs, which does not help the overall performance. The effect of trimming on symbolic steps and time may also vary depending on how interconnected the graph is. It would be worth looking at how many times trimming should be run to optimize its effectiveness. An interesting heuristic to look at would be to continue trimming until trimming only removes a small percentage of nodes; as then it starts being less effective and may take a toll on the overall runtime if done too many times. One could also choose to look at whether performing trimming in between iteration of the algorithm woudl further improve the runtime.
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master/master"
%%% End:
