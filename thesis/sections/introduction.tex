\documentclass[../master/master.tex]{subfiles}

\begin{document}
Graphs are one of the cornerstones in computer science; they are used in data organization,  program compilation (registry allocation, control-flow graphs), networks of communication and in particular model checking.

One of the main obstacles in model checking is so called \textit{state explosion} \cite{clarke_henzinger_veith_bloem_2018}, since the state space grows exponentially in the size of the model. Thus, model checking often has to deal with extremely large graphs \cite{pelanek_2004}. As our model size increases, running an algorithm on the explicit graph quickly becomes infeasible since the entire graph and/or the intermediate computations outgrow the main memory of the given machine. A solution to this problem is to find a more concise representation of graphs - one that does not have an exponential increase in storage usage, even if the graph size increases exponentially. For this reason, model checkers, e.g. NuSMV \cite{NUSMV, NUSMV2}, MCK \cite{MCK}, and LTSmin \cite{LTSmin}, use \textit{Binary Decision Diagrams} (BDD) \cite{bryant_1986} to reason about the state space. BDDs provide a canonical representation of boolean functions that in practice concisely describes the exponentially large truth-table. This can represent a graph by viewing an edge as a boolean relation between two nodes \cite{bryant_1992}; a so called \textit{symbolic representation}.

Efficient computation of strongly connected components (SCC) is very relevant in the field of model checking, for example for deciding emptines of BÃ¼chi automata \cite{spin}.  For strongly connected components in particular, we cannot just reuse conventional SCC algorithms that work for explicit graph representations (e.g. Tarjan's linear time algorithm \cite{tarjan_1971}). For example, the algorithm of Tarjan \cite{tarjan_1971} uses two depth-first searches to compute a spanning forest of the graph. A DFS is simply not possible on a symbolically reperesented graph, as it involves considering and labeling each node individually - something that is obviously impossible to do unless the graph is explicitly represented. Thus, in a symbolic setting our options are more limited; our main tool is the computation of the image and pre-image over sets of nodes. Such a computation is refered to as a symbolic step and time complexity in symbolic algorithms is normally measured in these.

Gentilini et al. \cite{linear} and Bloem et al \cite{lockstep} proposed two algorithms that compute SCCs on a graph represented with a BDD - so called \emph{symbolic} algorithms. The papers in question investigate algorithms that center around the computation of strongly connected components on symbolically represented graphs. The time complexities of the symbolic SCC decomposition algorithms in \cite{linear} (\textit{Linear}) and \cite{lockstep} (\textit{Lockstep}) have respective time complexities $\mathcal{O}(n)$ and $\mathcal{O}(n \log n)$. However, these time complexities does not necessarily reflect practical efficiency. For example, the average symbolic step in \textit{Linear} might be more time consuming, or the asymptotic advantage that \textit{Linear} has over \textit{Lockstep} might not outweigh the constants hidden in the $\mathcal{O} $-notation for practical applications. 

We investigate the practical difference between the two algorithms. To this end, we implement a small framework that can represent graphs as BDDs, building on top of the JavaBDD package \cite{whaley}. This framework facilitates the implementation of algorithms using a common API for performing symbolic operations and BDD operations; this allows a controlled comparison of them. 
When comparing, we ran the different algorithms on the same collection of graphs of varying size and structure.

We investigate a few improvements that could be made to the two proposed algorithms - these will also be included in our experiments. One such improvement is \textit{trimming}, suggested in \cite{lockstep}, which we apply to both \textit{Linear} and \textit{Lockstep}. Another one is \textit{edge restriction} - something that is done already in \cite{linear}, which we also try applying on \textit{Lockstep}. In total we examine 5 algorithms for SCC decomposition, including the two original algorithms. The results are analyzed with respect to the amount of symbolic steps taken and with respect to the practical runtime of the algorithms.

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master/master"
%%% End:
